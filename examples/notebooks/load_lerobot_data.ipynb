{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79954735",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This script demonstrates the use of `LeRobotDataset` class for handling and processing robotic datasets from Hugging Face.\n",
    "It illustrates how to load datasets, manipulate them, and apply transformations suitable for machine learning tasks in PyTorch.\n",
    "\n",
    "Features included in this script:\n",
    "- Viewing a dataset's metadata and exploring its properties.\n",
    "- Loading an existing dataset from the hub or a subset of it.\n",
    "- Accessing frames by episode number.\n",
    "- Using advanced dataset features like timestamp-based frame selection.\n",
    "- Demonstrating compatibility with PyTorch DataLoader for batch processing.\n",
    "\n",
    "The script ends with examples of how to batch process data using PyTorch's DataLoader.\n",
    "\"\"\"\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "import torch\n",
    "from huggingface_hub import HfApi\n",
    "\n",
    "import lerobot\n",
    "from lerobot.datasets.lerobot_dataset import LeRobotDataset, LeRobotDatasetMetadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc054390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of available datasets:\n",
      "lerobot/pusht\n"
     ]
    }
   ],
   "source": [
    "# We ported a number of existing datasets ourselves, use this to see the list:\n",
    "print(\"List of available datasets:\")\n",
    "if 'lerobot/pusht' in lerobot.available_datasets:\n",
    "    idx = lerobot.available_datasets.index('lerobot/pusht')\n",
    "    print(lerobot.available_datasets[idx])\n",
    "else:\n",
    "    print(\"pusht dataset is not available\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8cf50f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xipengw/miniconda3/envs/lerobot/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in 'list_datasets': tags. Will not be supported from version '1.0'.\n",
      "\n",
      "Use `filter` instead.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lerobot/pusht\n"
     ]
    }
   ],
   "source": [
    "# You can also browse through the datasets created/ported by the community on the hub using the hub api:\n",
    "hub_api = HfApi()\n",
    "\n",
    "repo_ids = [info.id for info in hub_api.list_datasets(task_categories=\"robotics\", tags=[\"LeRobot\"])]\n",
    "if 'lerobot/pusht' in repo_ids:\n",
    "    idx = repo_ids.index('lerobot/pusht')\n",
    "    print(repo_ids[idx])\n",
    "else:\n",
    "    print(\"pusht dataset is not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7548e6a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keys to access images from cameras: ds_meta.camera_keys=['observation.image']\n",
      "\n",
      "LeRobotDatasetMetadata({\n",
      "    Repository ID: 'lerobot/pusht',\n",
      "    Total episodes: '206',\n",
      "    Total frames: '25650',\n",
      "    Features: '['observation.image', 'observation.state', 'action', 'episode_index', 'frame_index', 'timestamp', 'next.reward', 'next.done', 'next.success', 'index', 'task_index']',\n",
      "})',\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Or simply explore them in your web browser directly at:\n",
    "# https://huggingface.co/datasets?other=LeRobot\n",
    "\n",
    "# Let's take this one for this example\n",
    "repo_id = \"lerobot/pusht\"\n",
    "# We can have a look and fetch its metadata to know more about it:\n",
    "ds_meta = LeRobotDatasetMetadata(repo_id)\n",
    "\n",
    "# By instantiating just this class, you can quickly access useful information about the content and the\n",
    "# structure of the dataset without downloading the actual data yet (only metadata files â€” which are\n",
    "# lightweight).\n",
    "\n",
    "# print(f\"Total number of episodes: {ds_meta.total_episodes}\")\n",
    "# print(f\"Average number of frames per episode: {ds_meta.total_frames / ds_meta.total_episodes:.3f}\")\n",
    "# print(f\"Frames per second used during data collection: {ds_meta.fps}\")\n",
    "# print(f\"Robot type: {ds_meta.robot_type}\")\n",
    "print(f\"keys to access images from cameras: {ds_meta.camera_keys=}\\n\")\n",
    "\n",
    "# print(\"Tasks:\")\n",
    "# print(ds_meta.tasks)\n",
    "# print(\"Features:\")\n",
    "# pprint(ds_meta.features)\n",
    "\n",
    "# You can also get a short summary by simply printing the object:\n",
    "print(ds_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e6eff4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected episodes: [0, 200]\n",
      "Number of episodes selected: 2\n",
      "Number of frames selected: 25650\n"
     ]
    }
   ],
   "source": [
    "# You can then load the actual dataset from the hub.\n",
    "# Either load any subset of episodes:\n",
    "dataset = LeRobotDataset(repo_id, episodes=[0, 200])\n",
    "# And see how many frames you have:\n",
    "print(f\"Selected episodes: {dataset.episodes}\")\n",
    "print(f\"Number of episodes selected: {dataset.num_episodes}\")\n",
    "print(f\"Number of frames selected: {dataset.num_frames}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44bff43d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of episodes selected: 206\n",
      "Number of frames selected: 25650\n"
     ]
    }
   ],
   "source": [
    "# Or simply load the entire dataset:\n",
    "dataset = LeRobotDataset(repo_id)\n",
    "print(f\"Number of episodes selected: {dataset.num_episodes}\")\n",
    "print(f\"Number of frames selected: {dataset.num_frames}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af096a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeRobotDatasetMetadata({\n",
      "    Repository ID: 'lerobot/pusht',\n",
      "    Total episodes: '206',\n",
      "    Total frames: '25650',\n",
      "    Features: '['observation.image', 'observation.state', 'action', 'episode_index', 'frame_index', 'timestamp', 'next.reward', 'next.done', 'next.success', 'index', 'task_index']',\n",
      "})',\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The previous metadata class is contained in the 'meta' attribute of the dataset:\n",
    "print(dataset.meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a25a3121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['observation.state', 'action', 'episode_index', 'frame_index', 'timestamp', 'next.reward', 'next.done', 'next.success', 'index', 'task_index'],\n",
      "    num_rows: 25650\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# LeRobotDataset actually wraps an underlying Hugging Face dataset\n",
    "# (see https://huggingface.co/docs/datasets for more information).\n",
    "print(dataset.hf_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25ca853e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 161\n"
     ]
    }
   ],
   "source": [
    "# LeRobot datasets also subclasses PyTorch datasets so you can do everything you know and love from working\n",
    "# with the latter, like iterating through the dataset.\n",
    "# The __getitem__ iterates over the frames of the dataset. Since our datasets are also structured by\n",
    "# episodes, you can access the frame indices of any episode using dataset.meta.episodes. Here, we access\n",
    "# frame indices associated to the first episode:\n",
    "episode_index = 0\n",
    "from_idx = dataset.meta.episodes[\"dataset_from_index\"][episode_index]\n",
    "to_idx = dataset.meta.episodes[\"dataset_to_index\"][episode_index]\n",
    "print(from_idx, to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e593d8cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([3, 96, 96])\n"
     ]
    }
   ],
   "source": [
    "# Then we grab all the image frames from the first camera:\n",
    "camera_key = dataset.meta.camera_keys[0]\n",
    "frames = [dataset[idx][camera_key] for idx in range(from_idx, to_idx)]\n",
    "# The objects returned by the dataset are all torch.Tensors\n",
    "print(type(frames[0]))\n",
    "print(frames[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3898308",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output\n",
    "import time\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "for frame_idx in range(0, len(frames)):\n",
    "    image = frames[frame_idx].permute(1, 2, 0).cpu().numpy()\n",
    "    # Display every frame slowly\n",
    "    clear_output(wait=True)\n",
    "    plt.clf()\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.title(f'Step: {frame_idx}')\n",
    "    display(plt.gcf())\n",
    "    # Add delay to slow down the rendering (adjust this value as needed)\n",
    "    time.sleep(0.01)  # 0.1 seconds = 10 FPS, increase for slower rendering\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d06fc5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dtype': 'video',\n",
      " 'names': ['height', 'width', 'channel'],\n",
      " 'shape': (96, 96, 3),\n",
      " 'video_info': {'has_audio': False,\n",
      "                'video.codec': 'av1',\n",
      "                'video.fps': 10.0,\n",
      "                'video.is_depth_map': False,\n",
      "                'video.pix_fmt': 'yuv420p'}}\n",
      "(96, 96, 3)\n"
     ]
    }
   ],
   "source": [
    "# Since we're using pytorch, the shape is in pytorch, channel-first convention (c, h, w).\n",
    "# We can compare this shape with the information available for that feature\n",
    "pprint(dataset.features[camera_key])\n",
    "# In particular:\n",
    "print(dataset.features[camera_key][\"shape\"])\n",
    "# The shape is in (h, w, c) which is a more universal format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a393149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For many machine learning applications we need to load the history of past observations or trajectories of\n",
    "# future actions. Our datasets can load previous and future frames for each key/modality, using timestamps\n",
    "# differences with the current loaded frame. For instance:\n",
    "delta_timestamps = {\n",
    "    # loads 4 images: 1 second before current frame, 500 ms before, 200 ms before, and current frame\n",
    "    camera_key: [-1, -0.5, -0.20, 0],\n",
    "    # loads 6 state vectors: 1.5 seconds before, 1 second before, ... 200 ms, 100 ms, and current frame\n",
    "    \"observation.state\": [-1.5, -1, -0.5, -0.20, -0.10, 0],\n",
    "    # loads 64 action vectors: current frame, 1 frame in the future, 2 frames, ... 63 frames in the future\n",
    "    \"action\": [t / dataset.fps for t in range(64)],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ae4efb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "dataset[0][camera_key].shape=torch.Size([4, 3, 96, 96])\n",
      "dataset[0]['observation.state'].shape=torch.Size([6, 2])\n",
      "dataset[0]['action'].shape=torch.Size([64, 2])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Note that in any case, these delta_timestamps values need to be multiples of (1/fps) so that added to any\n",
    "# timestamp, you still get a valid timestamp.\n",
    "\n",
    "dataset = LeRobotDataset(repo_id, delta_timestamps=delta_timestamps)\n",
    "print(f\"\\n{dataset[0][camera_key].shape=}\")  # (4, c, h, w)\n",
    "print(f\"{dataset[0]['observation.state'].shape=}\")  # (6, c)\n",
    "print(f\"{dataset[0]['action'].shape=}\\n\")  # (64, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "77292c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch[camera_key].shape=torch.Size([32, 4, 3, 96, 96])\n",
      "batch['observation.state'].shape=torch.Size([32, 6, 2])\n",
      "batch['action'].shape=torch.Size([32, 64, 2])\n"
     ]
    }
   ],
   "source": [
    "# Finally, our datasets are fully compatible with PyTorch dataloaders and samplers because they are just\n",
    "# PyTorch datasets.\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    num_workers=0,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "for batch in dataloader:\n",
    "    print(f\"{batch[camera_key].shape=}\")  # (32, 4, c, h, w)\n",
    "    print(f\"{batch['observation.state'].shape=}\")  # (32, 6, c)\n",
    "    print(f\"{batch['action'].shape=}\")  # (32, 64, c)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4e0cb31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "\n",
    "from lerobot.configs.types import FeatureType\n",
    "from lerobot.datasets.lerobot_dataset import LeRobotDataset, LeRobotDatasetMetadata\n",
    "from lerobot.datasets.utils import dataset_to_policy_features\n",
    "from lerobot.policies.diffusion.configuration_diffusion import DiffusionConfig\n",
    "from lerobot.policies.diffusion.modeling_diffusion import DiffusionPolicy\n",
    "from lerobot.policies.factory import make_pre_post_processors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "74333bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a directory to store the training checkpoint.\n",
    "output_directory = Path(\"outputs/train/example_pusht_diffusion\")\n",
    "output_directory.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ff8b5ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Select your device\n",
    "assert torch.cuda.is_available(), \"No GPU available\"\n",
    "device = torch.device(\"cuda\")\n",
    "device_str = \"cuda\"  # Use string for config, torch.device for actual operations\n",
    "# Number of offline training steps (we'll only do offline training for this example.)\n",
    "# Adjust as you prefer. 5000 steps are needed to get something worth evaluating.\n",
    "training_steps = 5000\n",
    "log_freq = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "17079366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# When starting from scratch (i.e. not from a pretrained policy), we need to specify 2 things before\n",
    "# creating the policy:\n",
    "#   - input/output shapes: to properly size the policy\n",
    "#   - dataset stats: for normalization and denormalization of input/outputs\n",
    "dataset_metadata = LeRobotDatasetMetadata(\"lerobot/pusht\")\n",
    "features = dataset_to_policy_features(dataset_metadata.features)\n",
    "output_features = {key: ft for key, ft in features.items() if ft.type is FeatureType.ACTION}\n",
    "input_features = {key: ft for key, ft in features.items() if key not in output_features}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b78cafc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Policies are initialized with a configuration class, in this case `DiffusionConfig`. For this example,\n",
    "# we'll just use the defaults and so no arguments other than input/output features need to be passed.\n",
    "cfg = DiffusionConfig(input_features=input_features, \n",
    "                      output_features=output_features, \n",
    "                      device=device_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "01c79c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can now instantiate our policy with this config and the dataset stats.\n",
    "policy = DiffusionPolicy(cfg)\n",
    "policy.train()\n",
    "policy.to(device)\n",
    "preprocessor, postprocessor = make_pre_post_processors(cfg, dataset_stats=dataset_metadata.stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f93c457d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this case with the standard configuration for Diffusion Policy, it is equivalent to this:\n",
    "delta_timestamps = {\n",
    "    # Load the previous image and state at -0.1 seconds before current frame,\n",
    "    # then load current image and state corresponding to 0.0 second.\n",
    "    \"observation.image\": [-0.1, 0.0],\n",
    "    \"observation.state\": [-0.1, 0.0],\n",
    "    # Load the previous action (-0.1), the next action to be executed (0.0),\n",
    "    # and 14 future actions with a 0.1 seconds spacing. All these actions will be\n",
    "    # used to supervise the policy.\n",
    "    \"action\": [-0.1, 0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 1.1, 1.2, 1.3, 1.4],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c43eb261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another policy-dataset interaction is with the delta_timestamps. Each policy expects a given number frames\n",
    "# which can differ for inputs, outputs and rewards (if there are some).\n",
    "delta_timestamps = {\n",
    "    \"observation.image\": [i / dataset_metadata.fps for i in cfg.observation_delta_indices],\n",
    "    \"observation.state\": [i / dataset_metadata.fps for i in cfg.observation_delta_indices],\n",
    "    \"action\": [i / dataset_metadata.fps for i in cfg.action_delta_indices],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ae5cb757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can then instantiate the dataset with these delta_timestamps configuration.\n",
    "dataset = LeRobotDataset(\"lerobot/pusht\", delta_timestamps=delta_timestamps, \n",
    "                        video_backend=\"pyav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d79fedd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then we create our optimizer and dataloader for offline training.\n",
    "optimizer = torch.optim.Adam(policy.parameters(), lr=1e-4)\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    num_workers=4,\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    "    pin_memory=device.type != \"cpu\",\n",
    "    drop_last=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0149e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run training loop.\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='torchvision.io._video_deprecation_warning')\n",
    "\n",
    "step = 0\n",
    "done = False\n",
    "while not done:\n",
    "    for batch in dataloader:\n",
    "        batch = preprocessor(batch)\n",
    "        loss, _ = policy.forward(batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if step % log_freq == 0:\n",
    "            print(f\"step: {step} loss: {loss.item():.3f}\")\n",
    "        step += 1\n",
    "        if step >= training_steps:\n",
    "            done = True\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2946cedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy.save_pretrained(output_directory)\n",
    "preprocessor.save_pretrained(output_directory)\n",
    "postprocessor.save_pretrained(output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c984f135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU: NVIDIA RTX PRO 6000 Blackwell Workstation Edition\n",
      "Loading weights from local directory\n",
      "Number of trainable parameters: 262,709,026\n"
     ]
    }
   ],
   "source": [
    "# Load the trained model and test on PushT environment\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Check for GPU availability\n",
    "assert torch.cuda.is_available(), \"No GPU available. SmolVLA requires CUDA.\"\n",
    "device = torch.device(\"cuda\")\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "# Load the trained policy\n",
    "pretrained_policy_path = Path(\"outputs/train/example_pusht_diffusion\")\n",
    "policy = DiffusionPolicy.from_pretrained(pretrained_policy_path)\n",
    "policy.eval()\n",
    "policy.to(device)\n",
    "print(f\"Number of trainable parameters: {sum(p.numel() for p in policy.parameters() if p.requires_grad):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9967981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from outputs/train/example_pusht_diffusion\n",
      "Policy device: cuda:0\n",
      "PushT environment created successfully\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "preprocessor, postprocessor = make_pre_post_processors(policy.config, pretrained_path=pretrained_policy_path)\n",
    "\n",
    "print(f\"Model loaded from {pretrained_policy_path}\")\n",
    "print(f\"Policy device: {next(policy.parameters()).device}\")\n",
    "\n",
    "# Create the PushT environment\n",
    "try:\n",
    "    import gym_pusht\n",
    "    env = gym.make(\"gym_pusht/PushT-v0\", render_mode=\"rgb_array\", obs_type=\"pixels_agent_pos\")\n",
    "    print(\"PushT environment created successfully\")\n",
    "except ImportError:\n",
    "    print(\"Warning: gym_pusht not installed. Install with: pip install gym-pusht\")\n",
    "    env = None\n",
    "except Exception as e:\n",
    "    print(f\"Error creating environment: {e}\")\n",
    "    env = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d7ac3318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward = 0.00, Success = False, Steps = 1\n",
      "Reward = 9.32, Success = False, Steps = 101\n",
      "Reward = 84.63, Success = False, Steps = 201\n"
     ]
    }
   ],
   "source": [
    "# Reset the environment\n",
    "observation, info = env.reset(seed=42)\n",
    "# Reset the policy's internal queue at the start of each episode\n",
    "policy.reset()\n",
    "episode_reward = 0\n",
    "frames_for_video = []\n",
    "max_steps = 500\n",
    "log_freq = 100\n",
    "for step in range(max_steps):\n",
    "    # Get current observation\n",
    "    current_image = torch.from_numpy(observation[\"pixels\"]).float() / 255.0\n",
    "    frames_for_video.append(current_image)\n",
    "    # Normalize image from [0, 255] to [0, 1] and permute to (C, H, W) for torch input\n",
    "    current_image = current_image.permute(2, 0, 1)\n",
    "    current_state = torch.from_numpy(observation[\"agent_pos\"]).float()\n",
    "\n",
    "    # Build observation dict for policy (single timestep, no temporal stacking)\n",
    "    # The policy's queue mechanism will handle the temporal dimension\n",
    "    # Shape: [batch, channels, height, width] for images, [batch, state_dim] for state\n",
    "\n",
    "    # Check input features\n",
    "    # print(input_features.keys())\n",
    "    batch = {\n",
    "        \"observation.image\": current_image.unsqueeze(0).to(device),  # [1, C, H, W]\n",
    "        \"observation.state\": current_state.unsqueeze(0).to(device),  # [1, state_dim]\n",
    "    }\n",
    "\n",
    "    # Get action from policy\n",
    "    actions = None\n",
    "    with torch.no_grad():\n",
    "        batch = preprocessor(batch)\n",
    "        actions = policy.select_action(batch)\n",
    "        actions = postprocessor(actions)\n",
    "        # Execute action in environment\n",
    "    assert actions is not None\n",
    "    action = actions[0].cpu().numpy()\n",
    "    observation, reward, terminated, truncated, info = env.step(action)\n",
    "    episode_reward += reward\n",
    "    success = info.get(\"success\", False)\n",
    "    if step % log_freq == 0:\n",
    "        print(f\"Reward = {episode_reward:.2f}, Success = {success}, Steps = {step + 1}\")\n",
    "    if success:\n",
    "        print(f\"Reward = {episode_reward:.2f}, Success = {success}, Steps = {step + 1}\")\n",
    "        break\n",
    "    if terminated or truncated:\n",
    "        break\n",
    " \n",
    "    # Execute action in environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f068d4c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output\n",
    "import time\n",
    "\n",
    "print(\"Visualizing first episode...\")\n",
    "plt.figure(figsize=(8, 8))\n",
    "for frame_idx in range(0, len(frames_for_video)):\n",
    "    image = frames_for_video[frame_idx]\n",
    "    # Display every frame slowly\n",
    "    clear_output(wait=True)\n",
    "    plt.clf()\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.title(f'Step: {frame_idx}')\n",
    "    display(plt.gcf())\n",
    "    # Add delay to slow down the rendering (adjust this value as needed)\n",
    "    time.sleep(0.01)  # 0.1 seconds = 10 FPS, increase for slower rendering\n",
    "plt.clf()\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1bd3dcf",
   "metadata": {},
   "source": [
    "## Start training SmolVLA with LeRobot\n",
    "\n",
    "#### Make sure you're logged in\n",
    "`hf auth login`\n",
    "#### Clone with LFS support\n",
    "```\n",
    "cd /tmp\n",
    "git lfs install\n",
    "GIT_LFS_SKIP_SMUDGE=1 git clone https://huggingface.co/annarborace01/smolvla-test\n",
    "cd smolvla-test\n",
    "```\n",
    "#### Fetch LFS files\n",
    "`git lfs pull`\n",
    "\n",
    "#### Create new repo on your account (via CLI)\n",
    "`hf repo create smolvla-test --repo-type model`\n",
    "\n",
    "#### Update remote and push\n",
    "`git remote set-url origin git@hf.co:annarborace01/smolvla-test`\n",
    "`git push -fu origin main`\n",
    "\n",
    "\n",
    "```\n",
    "python src/lerobot/scripts/lerobot_train.py \\\n",
    "  --policy.path=annarborace01/smolvla-test \\\n",
    "  --dataset.repo_id=lerobot/pusht \\\n",
    "  --batch_size=64 \\\n",
    "  --steps=20000 \\\n",
    "  --output_dir=outputs/train/my_smolvla_pusht \\\n",
    "  --job_name=my_smolvla_pusht_training \\\n",
    "  --policy.device=cuda \\\n",
    "  --wandb.enable=true \\\n",
    "  --policy.push_to_hub=false\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lerobot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
