{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10a7d31e",
   "metadata": {},
   "source": [
    "# Push T Task with PI Model\n",
    "\n",
    "This notebook demonstrates training and evaluating the Pi model on the PushT task.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d861ce5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "from lerobot.datasets.lerobot_dataset import LeRobotDataset, LeRobotDatasetMetadata\n",
    "from lerobot.configs.types import FeatureType\n",
    "from lerobot.datasets.utils import dataset_to_policy_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fed8a0",
   "metadata": {},
   "source": [
    "## 1. Load PushT Dataset\n",
    "\n",
    "First, let's load the PushT dataset and explore its properties.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3114d765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset metadata\n",
    "repo_id = \"lerobot/pusht\"\n",
    "ds_meta = LeRobotDatasetMetadata(repo_id)\n",
    "print(ds_meta)\n",
    "\n",
    "for key, value in ds_meta.features.items():\n",
    "    print(f\"{key}: {value.get('dtype', 'unknown')}, {value.get('shape', 'unknown')}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b8f641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the full dataset\n",
    "dataset = LeRobotDataset(repo_id)\n",
    "print(dataset)\n",
    "print(f\"Number of episodes: {dataset.num_episodes}\")\n",
    "print(f\"Number of frames: {dataset.num_frames}\")\n",
    "print(f\"FPS: {dataset.fps}\")\n",
    "\n",
    "for key, value in dataset.meta.episodes.features.items():\n",
    "    print(f\"{key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b89f1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_features = dataset_to_policy_features(dataset.meta.features)\n",
    "for key, value in policy_features.items():\n",
    "    print(f\"{key}: {value.type, value.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e40087",
   "metadata": {},
   "source": [
    "## 2. Visualize Sample Episode\n",
    "\n",
    "Let's visualize a sample episode from the dataset to understand what the task looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6770f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output\n",
    "import time\n",
    "\n",
    "# Get frames from first episode\n",
    "episode_index = 0\n",
    "from_idx = dataset.meta.episodes[\"dataset_from_index\"][episode_index]\n",
    "to_idx = dataset.meta.episodes[\"dataset_to_index\"][episode_index]\n",
    "\n",
    "camera_key = dataset.meta.camera_keys[0]\n",
    "frames = [dataset[idx][camera_key] for idx in range(from_idx, to_idx)] \n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "for frame_idx in range(len(frames)):\n",
    "    image = frames[frame_idx].permute(1, 2, 0).cpu().numpy()\n",
    "    clear_output(wait=True)\n",
    "    plt.clf()\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.title(f'Episode {episode_index}, Step: {frame_idx}')\n",
    "    display(plt.gcf())\n",
    "    time.sleep(0.01)\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcf8275",
   "metadata": {},
   "source": [
    "## 3. Initialize Pi Model\n",
    "\n",
    "Now we'll load the Pi model for training on this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b30cee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for GPU availability\n",
    "assert torch.cuda.is_available(), \"No GPU available. Pi requires CUDA.\"\n",
    "device = torch.device(\"cuda\")\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6795d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up output directory\n",
    "pi_model_name = \"pi05\"\n",
    "output_directory = Path(f\"outputs/train/pusht_{pi_model_name}\")\n",
    "output_directory.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeadd77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare input/output features for the policy\n",
    "dataset_metadata = LeRobotDatasetMetadata(\"lerobot/pusht\")\n",
    "features = dataset_to_policy_features(dataset_metadata.features)\n",
    "output_features = {key: ft for key, ft in features.items() if ft.type is FeatureType.ACTION}\n",
    "input_features = {key: ft for key, ft in features.items() if key not in output_features}\n",
    "\n",
    "print(\"Input features:\", list(input_features.keys()))\n",
    "print(\"Output features:\", list(output_features.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f447437c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lerobot.policies.pi05.configuration_pi05 import PI05Config\n",
    "# Initialize SmolVLA configuration and policy\n",
    "# Using pretrained SmolVLA checkpoint\n",
    "\n",
    "cfg = PI05Config(\n",
    "    input_features=input_features,\n",
    "    output_features=output_features,\n",
    "    device=\"cuda\",\n",
    "    #paligemma_variant=\"gemma_300m\",\n",
    "    #action_expert_variant=\"gemma_300m\",\n",
    "    pretrained_path=\"lerobot/pi05_base\",\n",
    ")\n",
    "\n",
    "print(\"VLA Config created successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990d0218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the policy\n",
    "from lerobot.policies.pi05.modeling_pi05 import PI05Policy\n",
    "from lerobot.policies.factory import make_pre_post_processors\n",
    "policy = PI05Policy(cfg)\n",
    "policy.train()\n",
    "policy.to(device)\n",
    "\n",
    "# Create pre/post processors\n",
    "preprocessor, postprocessor = make_pre_post_processors(cfg, dataset_stats=dataset_metadata.stats)\n",
    "\n",
    "print(f\"Policy loaded and moved to {device}\")\n",
    "print(f\"Number of trainable parameters: {sum(p.numel() for p in policy.parameters() if p.requires_grad):,}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0830ce13",
   "metadata": {},
   "source": [
    "## 4. Prepare Dataset with Delta Timestamps\n",
    "\n",
    "PI uses temporal information, so we need to configure delta timestamps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90f0a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another policy-dataset interaction is with the delta_timestamps. Each policy expects a given number frames\n",
    "# which can differ for inputs, outputs and rewards (if there are some).\n",
    "delta_timestamps = {\n",
    "    \"observation.image\": [0.0],\n",
    "    \"observation.state\": [0.0],\n",
    "    \"action\": [i / dataset_metadata.fps for i in cfg.action_delta_indices],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43d4628",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Delta timestamps configuration:\")\n",
    "for key, deltas in delta_timestamps.items():\n",
    "    print(f\"  {key}: {deltas}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d980e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset with temporal configuration\n",
    "dataset = LeRobotDataset(\n",
    "    \"lerobot/pusht\",\n",
    "    delta_timestamps=delta_timestamps,\n",
    ")\n",
    "\n",
    "print(f\"Dataset loaded with {dataset.num_frames} frames\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26dffbc5",
   "metadata": {},
   "source": [
    "## 5. Train SmolVLA Policy\n",
    "\n",
    "Now we'll train the SmolVLA model on the PushT dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad7b8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "training_steps = 20000\n",
    "batch_size = 8  # SmolVLA may need smaller batch size due to memory\n",
    "\n",
    "# Set up optimizer and scheduler\n",
    "optimizer_config = {\n",
    "    \"lr\":  2.5e-5,\n",
    "    \"weight_decay\": 1e-10,\n",
    "    \"betas\": (0.9, 0.95),\n",
    "    \"eps\": 1e-08\n",
    "}\n",
    "\n",
    "scheduler_config = {\n",
    "    \"num_warmup_steps\": 1000,\n",
    "    \"num_decay_steps\": 30000,\n",
    "    \"peak_lr\": 2.5e-5,\n",
    "    \"decay_lr\": 2.5e-06\n",
    "}\n",
    "\n",
    "grad_clip_norm = 1.0\n",
    "\n",
    "# Create AdamW optimizer\n",
    "optimizer = torch.optim.AdamW(\n",
    "    policy.parameters(),\n",
    "    lr=optimizer_config[\"lr\"],\n",
    "    weight_decay=optimizer_config[\"weight_decay\"],\n",
    "    betas=optimizer_config[\"betas\"],\n",
    "    eps=optimizer_config[\"eps\"]\n",
    ")\n",
    "\n",
    "# Create cosine decay with warmup scheduler\n",
    "def get_cosine_schedule_with_warmup(optimizer, num_warmup_steps, num_decay_steps, peak_lr, decay_lr):\n",
    "    \"\"\"\n",
    "    Create a learning rate scheduler with linear warmup and cosine decay.\n",
    "    \n",
    "    Args:\n",
    "        optimizer: PyTorch optimizer\n",
    "        num_warmup_steps: Number of steps for linear warmup\n",
    "        peak_lr: Peak learning rate after warmup\n",
    "        num_decay_steps: Total number of steps for cosine decay\n",
    "        decay_lr: Minimum learning rate at the end of decay\n",
    "    \"\"\"\n",
    "    def lr_lambda(current_step):\n",
    "        if current_step < num_warmup_steps:\n",
    "            # Linear warmup\n",
    "            return float(current_step) / float(max(1, num_warmup_steps))\n",
    "        else:\n",
    "            # Cosine decay\n",
    "            progress = float(current_step - num_warmup_steps) / float(max(1, num_decay_steps - num_warmup_steps))\n",
    "            progress = min(progress, 1.0)\n",
    "            cosine_decay = 0.5 * (1.0 + torch.cos(torch.tensor(progress * 3.14159265359))).item()\n",
    "            return (decay_lr / peak_lr) + (1.0 - decay_lr / peak_lr) * cosine_decay\n",
    "    \n",
    "    return torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
    "\n",
    "scheduler = get_cosine_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=scheduler_config[\"num_warmup_steps\"],\n",
    "    num_decay_steps=scheduler_config[\"num_decay_steps\"],\n",
    "    peak_lr=scheduler_config[\"peak_lr\"],\n",
    "    decay_lr=scheduler_config[\"decay_lr\"]\n",
    ")\n",
    "\n",
    "# Set up dataloader\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    num_workers=0,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    pin_memory=True,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "print(f\"Training configuration:\")\n",
    "print(f\"  Steps: {training_steps}\")\n",
    "print(f\"  Batch size: {batch_size}\")\n",
    "print(f\"  Learning rate: {optimizer_config['lr']}\")\n",
    "print(f\"  Weight decay: {optimizer_config['weight_decay']}\")\n",
    "print(f\"  Betas: {optimizer_config['betas']}\")\n",
    "print(f\"  Epsilon: {optimizer_config['eps']}\")\n",
    "print(f\"  Gradient clip norm: {grad_clip_norm}\")\n",
    "print(f\"  Warmup steps: {scheduler_config['num_warmup_steps']}\")\n",
    "print(f\"  Decay steps: {scheduler_config['num_decay_steps']}\")\n",
    "print(f\"  Peak LR: {scheduler_config['peak_lr']}\")\n",
    "print(f\"  Decay LR: {scheduler_config['decay_lr']}\")\n",
    "print(f\"  Batches per epoch: {len(dataloader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efc2e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='torchvision.io._video_deprecation_warning')\n",
    "\n",
    "step = 0\n",
    "done = False\n",
    "epoch = 0\n",
    "losses = []\n",
    "learning_rates = []\n",
    "\n",
    "print(\"Starting training...\\n\")\n",
    "# Add this right after creating the scheduler in Cell 18\n",
    "print(f\"Initial LR after scheduler creation: {optimizer.param_groups[0]['lr']:.8f}\")\n",
    "print(f\"Scheduler last_epoch: {scheduler.last_epoch}\")\n",
    "\n",
    "policy.train()\n",
    "\n",
    "log_freq = 10\n",
    "\n",
    "while not done:\n",
    "    epoch += 1\n",
    "    for batch in dataloader:\n",
    "        # Preprocess batch\n",
    "        batch = preprocessor(batch)\n",
    "        \n",
    "        # Forward pass\n",
    "        loss, _ = policy.forward(batch)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient clipping for stability\n",
    "        torch.nn.utils.clip_grad_norm_(policy.parameters(), max_norm=grad_clip_norm)\n",
    "        \n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        losses.append(loss.item())\n",
    "        # Track metrics\n",
    "        if step % log_freq == 0:\n",
    "            avg_loss = sum(losses[-log_freq:]) / len(losses[-log_freq:])\n",
    "            current_lr = optimizer.param_groups[0]['lr']\n",
    "            print(f\"Epoch {epoch}, Step {step:5d}: loss = {loss.item():.4f}, avg_loss = {avg_loss:.4f}, lr = {current_lr:.6f}\")\n",
    "            learning_rates.append(current_lr)\n",
    "                \n",
    "        step += 1\n",
    "        if step >= training_steps:\n",
    "            done = True\n",
    "            break\n",
    "\n",
    "print(f\"\\nTraining completed! Final loss: {losses[-1]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bd8843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training loss and learning rate\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8))\n",
    "\n",
    "# Plot loss\n",
    "ax1.plot(losses[200::200])\n",
    "ax1.set_xlabel('Training Step')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('SmolVLA Training Loss on PushT')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot learning rate schedule\n",
    "ax2.plot(learning_rates, color='orange')\n",
    "ax2.set_xlabel('Training Step')\n",
    "ax2.set_ylabel('Learning Rate')\n",
    "ax2.set_title('Learning Rate Schedule (Warmup + Cosine Decay)')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.axvline(x=scheduler_config['num_warmup_steps'], color='red', linestyle='--', label='End of Warmup')\n",
    "ax2.set_yscale('log')  # Log scale for better visualization\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7eef180",
   "metadata": {},
   "source": [
    "## 6. Save Trained Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b04abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "policy.save_pretrained(output_directory)\n",
    "preprocessor.save_pretrained(output_directory)\n",
    "postprocessor.save_pretrained(output_directory)\n",
    "\n",
    "print(f\"Model saved to {output_directory}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2521e5f5",
   "metadata": {},
   "source": [
    "## 7. Evaluate on PushT Environment\n",
    "\n",
    "Now let's test the trained SmolVLA model in the PushT environment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b32cc19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU: NVIDIA RTX PRO 6000 Blackwell Workstation Edition\n",
      "The PI05 model is a direct port of the OpenPI implementation. \n",
      "This implementation follows the original OpenPI structure for compatibility. \n",
      "Original implementation: https://github.com/Physical-Intelligence/openpi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Vision embedding key might need handling: model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.embeddings.patch_embedding.bias\n",
      "WARNING:root:Vision embedding key might need handling: model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.embeddings.patch_embedding.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: /home/xipengw/deeplearning/vla/lerobot/outputs/train/my_pi05_pusht/checkpoints/last/pretrained_model\n",
      "âœ“ Loaded state dict from model.safetensors\n",
      "Warning: Could not remap state dict keys: Error(s) in loading state_dict for PI05Policy:\n",
      "\tMissing key(s) in state_dict: \"model.paligemma_with_expert.paligemma.model.language_model.embed_tokens.weight\". \n",
      "Number of trainable parameters: 3,616,757,520\n",
      "Model loaded from /home/xipengw/deeplearning/vla/lerobot/outputs/train/my_pi05_pusht/checkpoints/last/pretrained_model\n",
      "Policy device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "from lerobot.policies.pi05.modeling_pi05 import PI05Policy\n",
    "from lerobot.policies.factory import make_pre_post_processors\n",
    "\n",
    "\n",
    "# Check for GPU availability\n",
    "assert torch.cuda.is_available(), \"No GPU available. Pi requires CUDA.\"\n",
    "device = torch.device(\"cuda\")\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "model_path = None\n",
    "output_directory = '/home/xipengw/deeplearning/vla/lerobot/outputs/train/my_pi05_pusht/checkpoints/last/pretrained_model'\n",
    "if False:\n",
    "    model_path = \"annarborace01/my-pi05-pusht\"\n",
    "else:\n",
    "    model_path = output_directory\n",
    "\n",
    "\n",
    "policy = PI05Policy.from_pretrained(model_path)\n",
    "print(f\"Number of trainable parameters: {sum(p.numel() for p in policy.parameters() if p.requires_grad):,}\")\n",
    "preprocessor, postprocessor = make_pre_post_processors(policy.config, pretrained_path=model_path)\n",
    "\n",
    "policy.eval()\n",
    "policy.to(device)\n",
    "\n",
    "print(f\"Model loaded from {model_path}\")\n",
    "print(f\"Policy device: {next(policy.parameters()).device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3742017e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PushT environment created successfully\n"
     ]
    }
   ],
   "source": [
    "# Create PushT environment\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "try:\n",
    "    import gym_pusht\n",
    "    env = gym.make(\"gym_pusht/PushT-v0\", render_mode=\"rgb_array\", obs_type=\"pixels_agent_pos\")\n",
    "    print(\"PushT environment created successfully\")\n",
    "except ImportError:\n",
    "    print(\"Warning: gym_pusht not installed. Install with: pip install gym-pusht\")\n",
    "    env = None\n",
    "except Exception as e:\n",
    "    print(f\"Error creating environment: {e}\")\n",
    "    env = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9346e770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU: NVIDIA RTX PRO 6000 Blackwell Workstation Edition\n",
      "Reward = 0.00, Success = False, Steps = 1\n",
      "Reward = 0.00, Success = False, Steps = 51\n",
      "Reward = 0.00, Success = False, Steps = 101\n",
      "Reward = 0.00, Success = False, Steps = 151\n",
      "Reward = 0.00, Success = False, Steps = 201\n",
      "Reward = 0.00, Success = False, Steps = 251\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check for GPU availability\n",
    "assert torch.cuda.is_available(), \"No GPU available. SmolVLA requires CUDA.\"\n",
    "device = torch.device(\"cuda\")\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "# Reset the environment\n",
    "observation, info = env.reset(seed=420)\n",
    "# Reset the policy's internal queue at the start of each episode\n",
    "policy.reset()\n",
    "\n",
    "frames_for_video = []\n",
    "max_steps = 1000\n",
    "log_freq = 50\n",
    "episode_reward = 0\n",
    "for step in range(max_steps):\n",
    "    # Get current observation\n",
    "    current_image = torch.from_numpy(observation[\"pixels\"]).float() / 255.0\n",
    "    frames_for_video.append(current_image)\n",
    "    # Normalize image from [0, 255] to [0, 1] and permute to (C, H, W) for torch input\n",
    "    current_image = current_image.permute(2, 0, 1)\n",
    "    current_state = torch.from_numpy(observation[\"agent_pos\"]).float()\n",
    "\n",
    "    # Build observation dict for policy (single timestep, no temporal stacking)\n",
    "    # The policy's queue mechanism will handle the temporal dimension\n",
    "    # Shape: [batch, channels, height, width] for images, [batch, state_dim] for state\n",
    "\n",
    "    # Check input features\n",
    "    # print(input_features.keys())\n",
    "    batch = {\n",
    "        \"observation.image\": current_image.unsqueeze(0).to(device),  # [1, C, H, W]\n",
    "        \"observation.state\": current_state.unsqueeze(0).to(device),  # [1, state_dim]\n",
    "        \"task\": \"Push the T-shaped block onto the T-shaped target.\"\n",
    "    }\n",
    "\n",
    "    # Get action from policy\n",
    "    actions = None\n",
    "    with torch.no_grad():\n",
    "        batch = preprocessor(batch)\n",
    "        actions = policy.select_action(batch)\n",
    "        actions = postprocessor(actions)\n",
    "        # Execute action in environment\n",
    "    assert actions is not None\n",
    "    action = actions[0].cpu().numpy()\n",
    "    observation, reward, terminated, truncated, info = env.step(action)\n",
    "    episode_reward += reward\n",
    "    success = info.get(\"success\", False)\n",
    "    if step % log_freq == 0:\n",
    "        print(f\"Reward = {episode_reward:.2f}, Success = {success}, Steps = {step + 1}\")\n",
    "    if success:\n",
    "        print(f\"Reward = {episode_reward:.2f}, Success = {success}, Steps = {step + 1}\")\n",
    "        break\n",
    "    if terminated or truncated:\n",
    "        break\n",
    " \n",
    "    # Execute action in environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7905315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output\n",
    "import time\n",
    "\n",
    "print(\"Visualizing first episode...\")\n",
    "plt.figure(figsize=(8, 8))\n",
    "for frame_idx in range(0, len(frames_for_video)):\n",
    "    image = frames_for_video[frame_idx]\n",
    "    # Display every frame slowly\n",
    "    clear_output(wait=True)\n",
    "    plt.clf()\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.title(f'Step: {frame_idx}')\n",
    "    display(plt.gcf())\n",
    "    # Add delay to slow down the rendering (adjust this value as needed)\n",
    "    time.sleep(0.01)  # 0.1 seconds = 10 FPS, increase for slower rendering\n",
    "plt.clf()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cec9424",
   "metadata": {},
   "source": [
    "## 9. Mess things around"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "484316f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU: NVIDIA RTX PRO 6000 Blackwell Workstation Edition\n",
      "Input features: ['observation.image', 'observation.state']\n",
      "Output features: ['action']\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "from lerobot.datasets.lerobot_dataset import LeRobotDataset, LeRobotDatasetMetadata\n",
    "from lerobot.configs.types import FeatureType\n",
    "from lerobot.datasets.utils import dataset_to_policy_features\n",
    "from lerobot.policies.pi05.modeling_pi05 import PI05Policy\n",
    "from lerobot.policies.factory import make_pre_post_processors\n",
    "\n",
    "# Check for GPU availability\n",
    "assert torch.cuda.is_available(), \"No GPU available. SmolVLA requires CUDA.\"\n",
    "device = torch.device(\"cuda\")\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "# Prepare input/output features for the policy\n",
    "dataset_metadata = LeRobotDatasetMetadata(\"lerobot/pusht\")\n",
    "features = dataset_to_policy_features(dataset_metadata.features)\n",
    "output_features = {key: ft for key, ft in features.items() if ft.type is FeatureType.ACTION}\n",
    "input_features = {key: ft for key, ft in features.items() if key not in output_features}\n",
    "\n",
    "print(\"Input features:\", list(input_features.keys()))\n",
    "print(\"Output features:\", list(output_features.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d3c667b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded with 25650 frames\n",
      "observation.image torch.Size([7, 3, 96, 96])\n",
      "observation.state torch.Size([7, 1, 2])\n",
      "action torch.Size([7, 50, 2])\n",
      "episode_index torch.Size([7])\n",
      "frame_index torch.Size([7])\n",
      "timestamp torch.Size([7])\n",
      "next.reward torch.Size([7])\n",
      "next.done torch.Size([7])\n",
      "next.success torch.Size([7])\n",
      "index torch.Size([7])\n",
      "task_index torch.Size([7])\n",
      "observation.image_is_pad torch.Size([7, 1])\n",
      "observation.state_is_pad torch.Size([7, 1])\n",
      "action_is_pad torch.Size([7, 50])\n",
      "task ['Push the T-shaped block onto the T-shaped target.', 'Push the T-shaped block onto the T-shaped target.', 'Push the T-shaped block onto the T-shaped target.', 'Push the T-shaped block onto the T-shaped target.', 'Push the T-shaped block onto the T-shaped target.', 'Push the T-shaped block onto the T-shaped target.', 'Push the T-shaped block onto the T-shaped target.']\n"
     ]
    }
   ],
   "source": [
    "from lerobot.policies.pi05.configuration_pi05 import PI05Config\n",
    "\n",
    "cfg = PI05Config(\n",
    "    input_features=input_features,\n",
    "    output_features=output_features,\n",
    "    device=\"cuda\",\n",
    "    paligemma_variant = \"gemma_300m\",\n",
    "    action_expert_variant = \"gemma_300m\",\n",
    "   \n",
    ")\n",
    "\n",
    "# Create pre/post processors\n",
    "preprocessor, postprocessor = make_pre_post_processors(cfg, dataset_stats=dataset_metadata.stats)\n",
    "\n",
    "# Another policy-dataset interaction is with the delta_timestamps. Each policy expects a given number frames\n",
    "# which can differ for inputs, outputs and rewards (if there are some).\n",
    "delta_timestamps = {\n",
    "    \"observation.image\": [0.0],\n",
    "    \"observation.state\": [0.0],\n",
    "    \"action\": [i / dataset_metadata.fps for i in cfg.action_delta_indices],\n",
    "}\n",
    "# Load dataset with temporal configuration\n",
    "dataset = LeRobotDataset(\n",
    "    \"lerobot/pusht\",\n",
    "    delta_timestamps=delta_timestamps,\n",
    ")\n",
    "\n",
    "print(f\"Dataset loaded with {dataset.num_frames} frames\")\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    num_workers=0,\n",
    "    batch_size=7,\n",
    "    shuffle=False,\n",
    "    pin_memory=True,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='torchvision.io._video_deprecation_warning')\n",
    "\n",
    "example_data = next(iter(dataloader))\n",
    "for key, value in example_data.items():\n",
    "    print(key, value.shape if isinstance(value, torch.Tensor) else value)\n",
    "\n",
    "\n",
    "batch = preprocessor(example_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12931398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action torch.Size([7, 50, 2])\n",
      "next.reward torch.Size([7])\n",
      "next.done torch.Size([7])\n",
      "next.truncated False\n",
      "info {}\n",
      "observation.image_is_pad torch.Size([7, 1])\n",
      "observation.state_is_pad torch.Size([7, 1])\n",
      "action_is_pad torch.Size([7, 50])\n",
      "task ['Task: Push the T-shaped block onto the T-shaped target., State: [112  -1 128 128 128 128 128 128 128 128 128 128 128 128 128 128 128 128\\n 128 128 128 128 128 128 128 128 128 128 128 128 128 128];\\nAction: ', 'Task: Push the T-shaped block onto the T-shaped target., State: [115  -1 128 128 128 128 128 128 128 128 128 128 128 128 128 128 128 128\\n 128 128 128 128 128 128 128 128 128 128 128 128 128 128];\\nAction: ', 'Task: Push the T-shaped block onto the T-shaped target., State: [117  -1 128 128 128 128 128 128 128 128 128 128 128 128 128 128 128 128\\n 128 128 128 128 128 128 128 128 128 128 128 128 128 128];\\nAction: ', 'Task: Push the T-shaped block onto the T-shaped target., State: [118  -1 128 128 128 128 128 128 128 128 128 128 128 128 128 128 128 128\\n 128 128 128 128 128 128 128 128 128 128 128 128 128 128];\\nAction: ', 'Task: Push the T-shaped block onto the T-shaped target., State: [119  -1 128 128 128 128 128 128 128 128 128 128 128 128 128 128 128 128\\n 128 128 128 128 128 128 128 128 128 128 128 128 128 128];\\nAction: ', 'Task: Push the T-shaped block onto the T-shaped target., State: [121  -1 128 128 128 128 128 128 128 128 128 128 128 128 128 128 128 128\\n 128 128 128 128 128 128 128 128 128 128 128 128 128 128];\\nAction: ', 'Task: Push the T-shaped block onto the T-shaped target., State: [128  -1 128 128 128 128 128 128 128 128 128 128 128 128 128 128 128 128\\n 128 128 128 128 128 128 128 128 128 128 128 128 128 128];\\nAction: ']\n",
      "index torch.Size([7])\n",
      "task_index torch.Size([7])\n",
      "observation.image torch.Size([7, 3, 96, 96])\n",
      "observation.state torch.Size([7, 1, 2])\n",
      "observation.language.tokens torch.Size([7, 200])\n",
      "observation.language.attention_mask torch.Size([7, 200])\n"
     ]
    }
   ],
   "source": [
    "for key, value in batch.items():\n",
    "    print(key, value.shape if isinstance(value, torch.Tensor) else value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85fe920d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameters: 1,683,014,416\n",
      "x_t.shape torch.Size([7, 50, 32])\n",
      "u_t.shape torch.Size([7, 50, 32])\n",
      "time_expanded.shape torch.Size([7, 1, 1])\n",
      "noise.shape torch.Size([7, 50, 32])\n",
      "actions.shape torch.Size([7, 50, 32])\n",
      "time.shape torch.Size([7])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 1. Expected size 2048 but got size 1024 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m policy\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     17\u001b[0m policy\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 18\u001b[0m loss, _ \u001b[38;5;241m=\u001b[39m \u001b[43mpolicy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/deeplearning/vla/lerobot/src/lerobot/policies/pi05/modeling_pi05.py:1159\u001b[0m, in \u001b[0;36mPI05Policy.forward\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m   1156\u001b[0m actions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_action(batch)\n\u001b[1;32m   1158\u001b[0m \u001b[38;5;66;03m# Compute loss (no separate state needed for PI05)\u001b[39;00m\n\u001b[0;32m-> 1159\u001b[0m losses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_masks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmasks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1161\u001b[0m \u001b[38;5;66;03m# Truncate losses to actual action dimensions\u001b[39;00m\n\u001b[1;32m   1162\u001b[0m original_action_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39moutput_features[ACTION]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/deeplearning/vla/lerobot/src/lerobot/policies/pi05/modeling_pi05.py:698\u001b[0m, in \u001b[0;36mPI05Pytorch.forward\u001b[0;34m(self, images, img_masks, tokens, masks, actions, noise, time)\u001b[0m\n\u001b[1;32m    695\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactions.shape\u001b[39m\u001b[38;5;124m\"\u001b[39m, actions\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m    696\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime.shape\u001b[39m\u001b[38;5;124m\"\u001b[39m, time\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m--> 698\u001b[0m prefix_embs, prefix_pad_masks, prefix_att_masks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_prefix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_masks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    699\u001b[0m suffix_embs, suffix_pad_masks, suffix_att_masks, adarms_cond \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_suffix(x_t, time)\n\u001b[1;32m    701\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    702\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpaligemma_with_expert\u001b[38;5;241m.\u001b[39mpaligemma\u001b[38;5;241m.\u001b[39mlanguage_model\u001b[38;5;241m.\u001b[39mlayers[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mself_attn\u001b[38;5;241m.\u001b[39mq_proj\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mdtype\n\u001b[1;32m    703\u001b[0m     \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39mbfloat16\n\u001b[1;32m    704\u001b[0m ):\n",
      "File \u001b[0;32m~/deeplearning/vla/lerobot/src/lerobot/policies/pi05/modeling_pi05.py:623\u001b[0m, in \u001b[0;36mPI05Pytorch.embed_prefix\u001b[0;34m(self, images, img_masks, tokens, masks)\u001b[0m\n\u001b[1;32m    620\u001b[0m num_lang_embs \u001b[38;5;241m=\u001b[39m lang_emb\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    621\u001b[0m att_masks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m num_lang_embs\n\u001b[0;32m--> 623\u001b[0m embs \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43membs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    624\u001b[0m pad_masks \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(pad_masks, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    625\u001b[0m att_masks \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(att_masks, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mbool, device\u001b[38;5;241m=\u001b[39mpad_masks\u001b[38;5;241m.\u001b[39mdevice)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 1. Expected size 2048 but got size 1024 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "\n",
    "\n",
    "# Reload the module\n",
    "from lerobot.policies.pi05 import modeling_pi05\n",
    "importlib.reload(modeling_pi05)\n",
    "\n",
    "from lerobot.policies.pi05.modeling_pi05 import PI05Policy\n",
    "cfg.debug_mode = True\n",
    "\n",
    "cfg.debug_mode = True\n",
    "policy = PI05Policy(cfg)\n",
    "\n",
    "print(f\"Number of trainable parameters: {sum(p.numel() for p in policy.parameters() if p.requires_grad):,}\")\n",
    "\n",
    "policy.train()\n",
    "policy.to(device)\n",
    "loss, _ = policy.forward(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7eb3746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actions.shape:  torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "actions = policy.select_action(batch)\n",
    "print(\"actions.shape: \", actions.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lerobot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
